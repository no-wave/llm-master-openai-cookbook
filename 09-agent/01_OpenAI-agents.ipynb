{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sG6pIZ-_7uRX"
   },
   "source": [
    "## OpenAI's Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3aqSlMc27noo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install openai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kwpk_H5_BnAl",
    "outputId": "89f732f4-db60-4b68-e937-f95ec84cdaeb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") or \\\n",
    "  getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lqkaleTAAjHK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You're a helpful assistant\",\n",
    "    model=\"gpt-4o-mini\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-zOBFhAEROm"
   },
   "source": [
    "## Running our Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "Bjn-gyR9BIn-",
    "outputId": "4d2f3062-7d78-4dae-8b1e-ecfebb594ba7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'물론이죠! 여기 짧은 이야기 하나 있어요.\\n\\n한 작은 마을에 노란색 꽃밭이 있었습니다. 마을 사람들은 그 꽃밭을 특별히 아끼고 사랑했죠. 그러던 어느 날, 꽃밭에 갑자기 파란색 꽃 한 송이가 피었습니다. 사람들은 처음에는 이상하게 여겼지만, 꽃은 점점 아름다움을 더해갔습니다.\\n\\n아이들은 파란색 꽃을 보며 상상의 나래를 펼쳤고, 어른들은 그 꽃의 특별함을 깨닫게 되었습니다. 결국, 마을 사람들은 서로의 다름을 인정하고 존중하는 법을 배우게 되었고, 파란색 꽃은 마을의 새로운 상징이 되었습니다.\\n\\n이렇게 작은 꽃 한 송이가 마을을 하나로 묶어주었다는 이야기였습니다.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=agent,\n",
    "    input=\"짧은 이야기를 만들어줄래.\"\n",
    ")\n",
    "result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBnhUepDBPHM",
    "outputId": "043f936a-7aea-4ec8-fdfd-a7aeb9ea2f39",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentUpdatedStreamEvent(new_agent=Agent(name='Assistant', instructions=\"You're a helpful assistant\", handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), type='agent_updated_stream_event')\n",
      "RawResponsesStreamEvent(data=ResponseCreatedEvent(response=Response(id='resp_67de62de1c5c81918c3905e8939b588f0194e2e59f1496c5', created_at=1742627550.0, error=None, incomplete_details=None, instructions=\"You're a helpful assistant\", metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), type='response.created'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseInProgressEvent(response=Response(id='resp_67de62de1c5c81918c3905e8939b588f0194e2e59f1496c5', created_at=1742627550.0, error=None, incomplete_details=None, instructions=\"You're a helpful assistant\", metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), type='response.in_progress'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', content=[], role='assistant', status='in_progress', type='message'), output_index=0, type='response.output_item.added'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseContentPartAddedEvent(content_index=0, item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text'), type='response.content_part.added'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='안', item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='녕하세요', item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='!', item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' 어떻게', item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' 도', item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='와', item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='드', item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='릴', item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='까요', item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='?', item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDoneEvent(content_index=0, item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, text='안녕하세요! 어떻게 도와드릴까요?', type='response.output_text.done'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseContentPartDoneEvent(content_index=0, item_id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', output_index=0, part=ResponseOutputText(annotations=[], text='안녕하세요! 어떻게 도와드릴까요?', type='output_text'), type='response.content_part.done'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', content=[ResponseOutputText(annotations=[], text='안녕하세요! 어떻게 도와드릴까요?', type='output_text')], role='assistant', status='completed', type='message'), output_index=0, type='response.output_item.done'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseCompletedEvent(response=Response(id='resp_67de62de1c5c81918c3905e8939b588f0194e2e59f1496c5', created_at=1742627550.0, error=None, incomplete_details=None, instructions=\"You're a helpful assistant\", metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', content=[ResponseOutputText(annotations=[], text='안녕하세요! 어떻게 도와드릴까요?', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=39, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=11, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=50), user=None, store=True), type='response.completed'), type='raw_response_event')\n",
      "RunItemStreamEvent(name='message_output_created', item=MessageOutputItem(agent=Agent(name='Assistant', instructions=\"You're a helpful assistant\", handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), raw_item=ResponseOutputMessage(id='msg_67de62dfeb008191a614704b0eb151b90194e2e59f1496c5', content=[ResponseOutputText(annotations=[], text='안녕하세요! 어떻게 도와드릴까요?', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item'), type='run_item_stream_event')\n"
     ]
    }
   ],
   "source": [
    "response = Runner.run_streamed(\n",
    "    starting_agent=agent,\n",
    "    input=\"여기, 안녕하세요.\"\n",
    ")\n",
    "async for event in response.stream_events():\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGQANyvXG9zJ",
    "outputId": "8f64469d-fe14-4d74-be40-6a0d0af51848",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한 작은 마을에 한 노인이 살고 있었습니다. 그는 매일 아침마다 마을의 넓은 공원에 나가서 나무와 꽃들에게 물을 주며 시간을 보냈습니다. 사람들은 그를 \"자연의 친구\"라고 불렀습니다.\n",
      "\n",
      "어느 날, 한 아이가 노인에게 다가와 물었습니다. \"왜 이렇게 열심히 나무에 물을 주시나요?\" 노인은 미소를 지으며 대답했습니다. \"우리가 언제까지나 함께 할 수는 없지만, 나무와 꽃은 그 자리를 지켜줄 거란다. 우리가 사랑한 그 자리에서 또 다른 생명들이 자랄 수 있도록.\"\n",
      "\n",
      "아이의 눈이 밝아지며 말했습니다. \"그러면 나도 사랑하는 나무를 키우고 싶어요!\" 노인은 고개를 끄덕이며 작은 나무를 하나 주었고, 아이는 그 나무를 정성껏 가꾸기로 다짐했습니다.\n",
      "\n",
      "세월이 흐른 후, 그 아이는 자란 나무 아래에서 친구들과 함께 놀며 행복한 시간을 보냈습니다. 그리고 노인이 정성스럽게 가꾸었던 공원은 여전히 아름다웠습니다. 누군가의 사랑은 결국 다른 이를 통해 세대를 넘어 계속 이어지는 법이니까요."
     ]
    }
   ],
   "source": [
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "# we do need to reinitialize our runner before re-executing\n",
    "response = Runner.run_streamed(\n",
    "    starting_agent=agent,\n",
    "    input=\"짧은 이야기를 들려주세요.\"\n",
    ")\n",
    "\n",
    "async for event in response.stream_events():\n",
    "    if event.type == \"raw_response_event\" and \\\n",
    "        isinstance(event.data, ResponseTextDeltaEvent):\n",
    "        print(event.data.delta, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Iixlv0sRMqr"
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tJz7BlwiNOa3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from agents import function_tool\n",
    "\n",
    "@function_tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\n",
    "    답을 제공해줘.\"\"\"\n",
    "    return x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "WnT4C9WBTO_M",
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=(\n",
    "        \"당신은 유용한 도우미입니다, 항상 \"\n",
    "        \"가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 \"\n",
    "        \"자신의 지식에 지나치게 의존하지 말고 대신 \"\n",
    "        \"도구를 사용하여 질문에 답하세요.\"\n",
    "    ),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[multiply]  # note that we expect a list of tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSOREQ-XUSVi",
    "outputId": "579e3dc2-832c-4d35-da30-5bcbd757248b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentUpdatedStreamEvent(new_agent=Agent(name='Assistant', instructions='당신은 유용한 도우미입니다, 항상 가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 자신의 지식에 지나치게 의존하지 말고 대신 도구를 사용하여 질문에 답하세요.', handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[FunctionTool(name='multiply', description='정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\\n답을 제공해줘.', params_json_schema={'properties': {'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}, 'required': ['x', 'y'], 'title': 'multiply_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7fc5a5f0fe20>, strict_json_schema=True)], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), type='agent_updated_stream_event')\n",
      "RawResponsesStreamEvent(data=ResponseCreatedEvent(response=Response(id='resp_67de62e5d6e08191b107bd28ca90d9cb02ea919c218a4a8e', created_at=1742627557.0, error=None, incomplete_details=None, instructions='당신은 유용한 도우미입니다, 항상 가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 자신의 지식에 지나치게 의존하지 말고 대신 도구를 사용하여 질문에 답하세요.', metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='multiply', parameters={'properties': {'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}, 'required': ['x', 'y'], 'title': 'multiply_args', 'type': 'object', 'additionalProperties': False}, strict=True, type='function', description='정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\\n답을 제공해줘.')], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), type='response.created'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseInProgressEvent(response=Response(id='resp_67de62e5d6e08191b107bd28ca90d9cb02ea919c218a4a8e', created_at=1742627557.0, error=None, incomplete_details=None, instructions='당신은 유용한 도우미입니다, 항상 가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 자신의 지식에 지나치게 의존하지 말고 대신 도구를 사용하여 질문에 답하세요.', metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='multiply', parameters={'properties': {'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}, 'required': ['x', 'y'], 'title': 'multiply_args', 'type': 'object', 'additionalProperties': False}, strict=True, type='function', description='정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\\n답을 제공해줘.')], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), type='response.in_progress'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseOutputItemAddedEvent(item=ResponseFunctionToolCall(arguments='', call_id='call_IeGt5X2mimjMDraHOADrNKKo', name='multiply', type='function_call', id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', status='in_progress'), output_index=0, type='response.output_item.added'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='{\"', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='x', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='\":', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='10', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='.', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='14', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta=',\"', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='y', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='\":', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='77', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='.', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='92', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDeltaEvent(delta='}', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseFunctionCallArgumentsDoneEvent(arguments='{\"x\":10.14,\"y\":77.92}', item_id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', output_index=0, type='response.function_call_arguments.done'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseOutputItemDoneEvent(item=ResponseFunctionToolCall(arguments='{\"x\":10.14,\"y\":77.92}', call_id='call_IeGt5X2mimjMDraHOADrNKKo', name='multiply', type='function_call', id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', status='completed'), output_index=0, type='response.output_item.done'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseCompletedEvent(response=Response(id='resp_67de62e5d6e08191b107bd28ca90d9cb02ea919c218a4a8e', created_at=1742627557.0, error=None, incomplete_details=None, instructions='당신은 유용한 도우미입니다, 항상 가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 자신의 지식에 지나치게 의존하지 말고 대신 도구를 사용하여 질문에 답하세요.', metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseFunctionToolCall(arguments='{\"x\":10.14,\"y\":77.92}', call_id='call_IeGt5X2mimjMDraHOADrNKKo', name='multiply', type='function_call', id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', status='completed')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='multiply', parameters={'properties': {'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}, 'required': ['x', 'y'], 'title': 'multiply_args', 'type': 'object', 'additionalProperties': False}, strict=True, type='function', description='정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\\n답을 제공해줘.')], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=355, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=22, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=377), user=None, store=True), type='response.completed'), type='raw_response_event')\n",
      "RunItemStreamEvent(name='tool_called', item=ToolCallItem(agent=Agent(name='Assistant', instructions='당신은 유용한 도우미입니다, 항상 가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 자신의 지식에 지나치게 의존하지 말고 대신 도구를 사용하여 질문에 답하세요.', handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[FunctionTool(name='multiply', description='정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\\n답을 제공해줘.', params_json_schema={'properties': {'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}, 'required': ['x', 'y'], 'title': 'multiply_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7fc5a5f0fe20>, strict_json_schema=True)], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), raw_item=ResponseFunctionToolCall(arguments='{\"x\":10.14,\"y\":77.92}', call_id='call_IeGt5X2mimjMDraHOADrNKKo', name='multiply', type='function_call', id='fc_67de62e682e08191a5dd4c7eec7d7d2102ea919c218a4a8e', status='completed'), type='tool_call_item'), type='run_item_stream_event')\n",
      "RunItemStreamEvent(name='tool_output', item=ToolCallOutputItem(agent=Agent(name='Assistant', instructions='당신은 유용한 도우미입니다, 항상 가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 자신의 지식에 지나치게 의존하지 말고 대신 도구를 사용하여 질문에 답하세요.', handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[FunctionTool(name='multiply', description='정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\\n답을 제공해줘.', params_json_schema={'properties': {'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}, 'required': ['x', 'y'], 'title': 'multiply_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7fc5a5f0fe20>, strict_json_schema=True)], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), raw_item={'call_id': 'call_IeGt5X2mimjMDraHOADrNKKo', 'output': '790.1088000000001', 'type': 'function_call_output'}, output=790.1088000000001, type='tool_call_output_item'), type='run_item_stream_event')\n",
      "RawResponsesStreamEvent(data=ResponseCreatedEvent(response=Response(id='resp_67de62e72c40819189e23eb0790353c002ea919c218a4a8e', created_at=1742627559.0, error=None, incomplete_details=None, instructions='당신은 유용한 도우미입니다, 항상 가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 자신의 지식에 지나치게 의존하지 말고 대신 도구를 사용하여 질문에 답하세요.', metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='multiply', parameters={'properties': {'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}, 'required': ['x', 'y'], 'title': 'multiply_args', 'type': 'object', 'additionalProperties': False}, strict=True, type='function', description='정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\\n답을 제공해줘.')], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), type='response.created'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseInProgressEvent(response=Response(id='resp_67de62e72c40819189e23eb0790353c002ea919c218a4a8e', created_at=1742627559.0, error=None, incomplete_details=None, instructions='당신은 유용한 도우미입니다, 항상 가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 자신의 지식에 지나치게 의존하지 말고 대신 도구를 사용하여 질문에 답하세요.', metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='multiply', parameters={'properties': {'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}, 'required': ['x', 'y'], 'title': 'multiply_args', 'type': 'object', 'additionalProperties': False}, strict=True, type='function', description='정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\\n답을 제공해줘.')], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=None, user=None, store=True), type='response.in_progress'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', content=[], role='assistant', status='in_progress', type='message'), output_index=0, type='response.output_item.added'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseContentPartAddedEvent(content_index=0, item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text'), type='response.content_part.added'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='10', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='.', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='14', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='에', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' ', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='77', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='.', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='92', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='를', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' 곱', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='한', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' 값', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='은', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' 약', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta=' ', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='790', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='.', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='11', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='입니다', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDeltaEvent(content_index=0, delta='.', item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, type='response.output_text.delta'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseTextDoneEvent(content_index=0, item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, text='10.14에 77.92를 곱한 값은 약 790.11입니다.', type='response.output_text.done'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseContentPartDoneEvent(content_index=0, item_id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', output_index=0, part=ResponseOutputText(annotations=[], text='10.14에 77.92를 곱한 값은 약 790.11입니다.', type='output_text'), type='response.content_part.done'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', content=[ResponseOutputText(annotations=[], text='10.14에 77.92를 곱한 값은 약 790.11입니다.', type='output_text')], role='assistant', status='completed', type='message'), output_index=0, type='response.output_item.done'), type='raw_response_event')\n",
      "RawResponsesStreamEvent(data=ResponseCompletedEvent(response=Response(id='resp_67de62e72c40819189e23eb0790353c002ea919c218a4a8e', created_at=1742627559.0, error=None, incomplete_details=None, instructions='당신은 유용한 도우미입니다, 항상 가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 자신의 지식에 지나치게 의존하지 말고 대신 도구를 사용하여 질문에 답하세요.', metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', content=[ResponseOutputText(annotations=[], text='10.14에 77.92를 곱한 값은 약 790.11입니다.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='multiply', parameters={'properties': {'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}, 'required': ['x', 'y'], 'title': 'multiply_args', 'type': 'object', 'additionalProperties': False}, strict=True, type='function', description='정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\\n답을 제공해줘.')], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None), status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=391, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=23, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=414), user=None, store=True), type='response.completed'), type='raw_response_event')\n",
      "RunItemStreamEvent(name='message_output_created', item=MessageOutputItem(agent=Agent(name='Assistant', instructions='당신은 유용한 도우미입니다, 항상 가능하면 항상 제공된 도구를 사용하세요. 하지 마세요 자신의 지식에 지나치게 의존하지 말고 대신 도구를 사용하여 질문에 답하세요.', handoff_description=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[FunctionTool(name='multiply', description='정확한 답을 제공하기 위해 `x`와 `y`를 곱합니다.\\n답을 제공해줘.', params_json_schema={'properties': {'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}, 'required': ['x', 'y'], 'title': 'multiply_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x7fc5a5f0fe20>, strict_json_schema=True)], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again'), raw_item=ResponseOutputMessage(id='msg_67de62e7a8bc81918e7c3cd42d643dec02ea919c218a4a8e', content=[ResponseOutputText(annotations=[], text='10.14에 77.92를 곱한 값은 약 790.11입니다.', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item'), type='run_item_stream_event')\n"
     ]
    }
   ],
   "source": [
    "response = Runner.run_streamed(\n",
    "    starting_agent=agent,\n",
    "    input=\"10.14에 77.92를 곱한 값은 무엇인가요?\"\n",
    ")\n",
    "\n",
    "async for event in response.stream_events():\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VhFvNVowUrd5",
    "outputId": "c572523c-e86a-4925-9010-367387766b5a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Current Agent: Assistant\n",
      "{\"x\":10.14,\"y\":77.92}\n",
      "> Tool Called, name: multiply\n",
      "> Tool Called, args: {\"x\":10.14,\"y\":77.92}\n",
      "> Tool Output: 790.1088000000001\n",
      "10.14에 77.92를 곱한 값은 약 790.11입니다."
     ]
    }
   ],
   "source": [
    "from openai.types.responses import (\n",
    "    ResponseFunctionCallArgumentsDeltaEvent,  # tool call streaming\n",
    "    ResponseCreatedEvent,  # start of new event like tool call or final answer\n",
    ")\n",
    "\n",
    "response = Runner.run_streamed(\n",
    "    starting_agent=agent,\n",
    "    input=\"10.14에 77.92를 곱한 값은 무엇인가요?\"\n",
    ")\n",
    "\n",
    "async for event in response.stream_events():\n",
    "    if event.type == \"raw_response_event\":\n",
    "        if isinstance(event.data, ResponseFunctionCallArgumentsDeltaEvent):\n",
    "            # this is streamed parameters for our tool call\n",
    "            print(event.data.delta, end=\"\", flush=True)\n",
    "        elif isinstance(event.data, ResponseTextDeltaEvent):\n",
    "            # this is streamed final answer tokens\n",
    "            print(event.data.delta, end=\"\", flush=True)\n",
    "    elif event.type == \"agent_updated_stream_event\":\n",
    "        # this tells us which agent is currently in use\n",
    "        print(f\"> Current Agent: {event.new_agent.name}\")\n",
    "    elif event.type == \"run_item_stream_event\":\n",
    "        # these are events containing info that we'd typically\n",
    "        # stream out to a user or some downstream process\n",
    "        if event.name == \"tool_called\":\n",
    "            # this is the collection of our _full_ tool call after our tool\n",
    "            # tokens have all been streamed\n",
    "            print()\n",
    "            print(f\"> Tool Called, name: {event.item.raw_item.name}\")\n",
    "            print(f\"> Tool Called, args: {event.item.raw_item.arguments}\")\n",
    "        elif event.name == \"tool_output\":\n",
    "            # this is the response from our tool execution\n",
    "            print(f\"> Tool Output: {event.item.raw_item['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqqWET4O93il"
   },
   "source": [
    "## Guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "I1LT_UpiXFg0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# define structure of output for any guardrail agents\n",
    "class GuardrailOutput(BaseModel):\n",
    "    is_triggered: bool\n",
    "    reasoning: str\n",
    "\n",
    "# define an agent that checks if user is asking about political opinions\n",
    "politics_agent = Agent(\n",
    "    name=\"Politics check\",\n",
    "    instructions=\"사용자가 정치적 의견을 묻는지 확인하세요.\",\n",
    "    output_type=GuardrailOutput,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4kgYMC9A7WP",
    "outputId": "7660cdce-00f3-41c9-812c-691fd8a85919",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunResult(input='미국의 트럼프 2기에 대해 어떻게 생각하시나요? 한글로 대답', new_items=[MessageOutputItem(agent=Agent(name='Politics check', instructions='사용자가 정치적 의견을 묻는지 확인하세요.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=<class '__main__.GuardrailOutput'>, hooks=None, tool_use_behavior='run_llm_again'), raw_item=ResponseOutputMessage(id='msg_67de62eb39ec8191b60f66f60caa593e07c8bf989960b4db', content=[ResponseOutputText(annotations=[], text='{\"is_triggered\":true,\"reasoning\":\"이 질문은 특정 정치적 인물과 그의 재임에 대한 의견을 묻고 있습니다. 이는 정치적 의견 요청에 해당합니다.\"}', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')], raw_responses=[ModelResponse(output=[ResponseOutputMessage(id='msg_67de62eb39ec8191b60f66f60caa593e07c8bf989960b4db', content=[ResponseOutputText(annotations=[], text='{\"is_triggered\":true,\"reasoning\":\"이 질문은 특정 정치적 인물과 그의 재임에 대한 의견을 묻고 있습니다. 이는 정치적 의견 요청에 해당합니다.\"}', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=112, output_tokens=42, total_tokens=154), referenceable_id='resp_67de62eae48c819199d0c49b5255e00407c8bf989960b4db')], final_output=GuardrailOutput(is_triggered=True, reasoning='이 질문은 특정 정치적 인물과 그의 재임에 대한 의견을 묻고 있습니다. 이는 정치적 의견 요청에 해당합니다.'), input_guardrail_results=[], output_guardrail_results=[], _last_agent=Agent(name='Politics check', instructions='사용자가 정치적 의견을 묻는지 확인하세요.', handoff_description=None, handoffs=[], model=None, model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=<class '__main__.GuardrailOutput'>, hooks=None, tool_use_behavior='run_llm_again'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"미국의 트럼프 2기에 대해 어떻게 생각하시나요? 한글로 대답\"\n",
    "\n",
    "result = await Runner.run(\n",
    "    starting_agent=politics_agent, \n",
    "    input=query\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yrS4dT5mC7jN",
    "outputId": "6e464d4f-ecbb-4aed-c0d4-208fcfcc9f17",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GuardrailOutput(is_triggered=True, reasoning='이 질문은 특정 정치적 인물과 그의 재임에 대한 의견을 묻고 있습니다. 이는 정치적 의견 요청에 해당합니다.')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "o3UQIt-qBLTK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from agents import (\n",
    "    GuardrailFunctionOutput,\n",
    "    RunContextWrapper,\n",
    "    input_guardrail\n",
    ")\n",
    "\n",
    "# this is the guardrail function that returns GuardrailFunctionOutput object\n",
    "@input_guardrail\n",
    "async def politics_guardrail(\n",
    "    ctx: RunContextWrapper[None],\n",
    "    agent: Agent,\n",
    "    input: str,\n",
    ") -> GuardrailFunctionOutput:\n",
    "    # run agent to check if guardrail is triggered\n",
    "    response = await Runner.run(starting_agent=politics_agent, input=input)\n",
    "    # format response into GuardrailFunctionOutput\n",
    "    return GuardrailFunctionOutput(\n",
    "        output_info=response.final_output,\n",
    "        tripwire_triggered=response.final_output.is_triggered,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "_JYELjOSFoED",
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=(\n",
    "        \"당신은 유용한 assistants입니다.\"\n",
    "        \"가능하면 제공된 도구를 사용하세요.\"\n",
    "        \"자신의 지식에 지나치게 의존하지 말고 대신.\"\n",
    "        \"도구를 사용하여 질문에 답하세요.\"\n",
    "    ),\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[multiply],\n",
    "    input_guardrails=[politics_guardrail],  # note this is a list of guardrails\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxYq9Aq0GIv6"
   },
   "source": [
    "Now let's run it! We'll stick with `Runner.run` for the sake of brevity:\n",
    "이제 실행해 봅시다! 간결함을 위해 `Runner.run`을 계속 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "GKDUcBYMGGcG",
    "outputId": "e512f6d0-fabb-44a0-c5ce-7a591d2824e1",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.14에 77.92를 곱한 값은 790.11입니다.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=agent,\n",
    "    input=\"10.14에 77.92를 곱한 값은 무엇인가요?\"\n",
    ")\n",
    "result.final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5sN23B_HcPn"
   },
   "source": [
    "Let's see if our guardrail will trigger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "-tncyfxYGdRn",
    "outputId": "c35a415e-0d41-487d-9753-cf0151350039",
    "tags": []
   },
   "outputs": [
    {
     "ename": "InputGuardrailTripwireTriggered",
     "evalue": "Guardrail InputGuardrail triggered tripwire",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInputGuardrailTripwireTriggered\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Runner\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m      2\u001b[0m     starting_agent\u001b[38;5;241m=\u001b[39magent,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m미국의 트럼프 2기에 대해 어떻게 생각하시나요? 한글로 대답?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/agents/run.py:210\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(cls, starting_agent, input, context, max_turns, hooks, run_config)\u001b[0m\n\u001b[1;32m    205\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m current_turn \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 210\u001b[0m     input_guardrail_results, turn_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_input_guardrails(\n\u001b[1;32m    212\u001b[0m             starting_agent,\n\u001b[1;32m    213\u001b[0m             starting_agent\u001b[38;5;241m.\u001b[39minput_guardrails\n\u001b[1;32m    214\u001b[0m             \u001b[38;5;241m+\u001b[39m (run_config\u001b[38;5;241m.\u001b[39minput_guardrails \u001b[38;5;129;01mor\u001b[39;00m []),\n\u001b[1;32m    215\u001b[0m             copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28minput\u001b[39m),\n\u001b[1;32m    216\u001b[0m             context_wrapper,\n\u001b[1;32m    217\u001b[0m         ),\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_single_turn(\n\u001b[1;32m    219\u001b[0m             agent\u001b[38;5;241m=\u001b[39mcurrent_agent,\n\u001b[1;32m    220\u001b[0m             original_input\u001b[38;5;241m=\u001b[39moriginal_input,\n\u001b[1;32m    221\u001b[0m             generated_items\u001b[38;5;241m=\u001b[39mgenerated_items,\n\u001b[1;32m    222\u001b[0m             hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    223\u001b[0m             context_wrapper\u001b[38;5;241m=\u001b[39mcontext_wrapper,\n\u001b[1;32m    224\u001b[0m             run_config\u001b[38;5;241m=\u001b[39mrun_config,\n\u001b[1;32m    225\u001b[0m             should_run_agent_start_hooks\u001b[38;5;241m=\u001b[39mshould_run_agent_start_hooks,\n\u001b[1;32m    226\u001b[0m         ),\n\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     turn_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_single_turn(\n\u001b[1;32m    230\u001b[0m         agent\u001b[38;5;241m=\u001b[39mcurrent_agent,\n\u001b[1;32m    231\u001b[0m         original_input\u001b[38;5;241m=\u001b[39moriginal_input,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m         should_run_agent_start_hooks\u001b[38;5;241m=\u001b[39mshould_run_agent_start_hooks,\n\u001b[1;32m    237\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/lecture/lib/python3.11/site-packages/agents/run.py:805\u001b[0m, in \u001b[0;36mRunner._run_input_guardrails\u001b[0;34m(cls, agent, guardrails, input, context)\u001b[0m\n\u001b[1;32m    798\u001b[0m         t\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m    799\u001b[0m     _error_tracing\u001b[38;5;241m.\u001b[39mattach_error_to_current_span(\n\u001b[1;32m    800\u001b[0m         SpanError(\n\u001b[1;32m    801\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGuardrail tripwire triggered\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    802\u001b[0m             data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguardrail\u001b[39m\u001b[38;5;124m\"\u001b[39m: result\u001b[38;5;241m.\u001b[39mguardrail\u001b[38;5;241m.\u001b[39mget_name()},\n\u001b[1;32m    803\u001b[0m         )\n\u001b[1;32m    804\u001b[0m     )\n\u001b[0;32m--> 805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InputGuardrailTripwireTriggered(result)\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     guardrail_results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "\u001b[0;31mInputGuardrailTripwireTriggered\u001b[0m: Guardrail InputGuardrail triggered tripwire"
     ]
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=agent,\n",
    "    input=\"미국의 트럼프 2기에 대해 어떻게 생각하시나요? 한글로 대답?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnVc_II-IcRg"
   },
   "source": [
    "## Conversational Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "wK558-qII5WA",
    "outputId": "5eaf5b88-18ef-4d4b-82ac-bf8511d519f3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'그 숫자를 기억했습니다: 10.645. 도움이 필요하시면 말씀해 주세요!'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=agent,\n",
    "    input=\"10.645라는 숫자를 기억해 주세요.\"\n",
    ")\n",
    "result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xs-buAAvJh8F",
    "outputId": "3b889236-2a26-4c91-bcca-45733518241d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': '10.645라는 숫자를 기억해 주세요.', 'role': 'user'},\n",
       " {'id': 'msg_67de63916e0481918f35f3e82ea01e64098f9ee6d31dd742',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': '그 숫자를 기억했습니다: 10.645. 도움이 필요하시면 말씀해 주세요!',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_input_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "y4WKSTObJokR",
    "outputId": "01331fad-5e8c-4e64-86cd-a3470432d462",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.645와 113.932를 곱한 결과는 1212.80614입니다. 더 필요하신 정보가 있으면 말씀해 주세요!'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = await Runner.run(\n",
    "    starting_agent=agent,\n",
    "    input=result.to_input_list() + [\n",
    "        {\"role\": \"user\", \"content\": \"마지막 숫자에 113.932를 곱합니다.\"}\n",
    "    ]\n",
    ")\n",
    "result.final_output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
